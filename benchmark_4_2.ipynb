{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Single Train/ Multiple Output BCNN \n",
    "\n",
    "1. BCNN -base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import theano\n",
    "import pymc3 as pm\n",
    "import theano.tensor as T\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "sns.set_style('white')\n",
    "import lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import data_utils\n",
    "\n",
    "Train_x, Train_y, Test_x, Test_y = data_utils.load_data()\n",
    "\n",
    "\n",
    "Train_x = np.asarray(Train_x)\n",
    "Train_y = np.asarray(Train_y)\n",
    "Test_x  = np.asarray(Test_x)\n",
    "Test_y  = np.asarray(Test_y)\n",
    "\n",
    "## Training and Testing Input\n",
    "\n",
    "X_train_single = Train_x[200:1700]\n",
    "\n",
    "X_test_multi = Train_x[:200]\n",
    "## Training and Testing Output\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "y = np.load('../behav_Exp/pri_sec_emotion.npy')\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = Train_y[200:1700]\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_test = mlb.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Reshape the input value\n",
    "\n",
    "X_train = X_train_single.reshape(X_train_single.shape[0], 1, 48, 48)\n",
    "X_test  = X_test_multi.reshape(X_test_multi.shape[0], 1, 48, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# BCNN on FER2000 First Tryout\n",
    "## remove dropout for its issue for shape inconsistency \n",
    "import lasagne\n",
    "total_size = len(y_train)\n",
    "ann_input_minibatch = pm.Minibatch(X_train, batch_size = 50)\n",
    "ann_output_minibatch = pm.Minibatch(y_train, batch_size = 50)\n",
    "\n",
    "\n",
    "n_hidden = 100\n",
    "\n",
    "# Initialize random weights between each layer\n",
    "\n",
    "init_1 = np.random.randn( 32, 1, 5, 5)\n",
    "init_2 = np.random.randn(32, 32, 5, 5)\n",
    "init_out = np.random.randn(9*9*32, 7)\n",
    "    \n",
    "with pm.Model() as neural_network:\n",
    "    \n",
    "    # Priors for Weight\n",
    "    c_in_1 = pm.Cauchy('r_in_1',-1, 2.5)\n",
    "    c_1_2 =  pm.Cauchy('r_1_2', 0, 2)\n",
    "    c_2_out = pm.Cauchy('r_2_out',0,1.5)\n",
    "\n",
    "    # Weights from input to hidden layer\n",
    "    weights_in_1 = pm.Normal('w_in_1',0.3, c_in_1, \n",
    "                             shape=( 32, 1, 5, 5), \n",
    "                             testval = init_1)\n",
    "    \n",
    "    weights_1_2  = pm.Normal('w_1_2',0.2, c_1_2, \n",
    "                            shape =(32, 32, 5, 5),\n",
    "                            testval = init_2)\n",
    "     \n",
    "    weights_2_out = pm.Normal('w_2_out',0.3, c_2_out, \n",
    "                            shape=(9*9*32, 7), \n",
    "                            testval = init_out)\n",
    "    \n",
    "    # Build neural-network using tanh activation function\n",
    "    in_1 = lasagne.layers.InputLayer((None, 1, 48, 48), \n",
    "                                       input_var=ann_input_minibatch)\n",
    "    \n",
    "    conv_1 = lasagne.layers.Conv2DLayer(in_1, num_filters=32, filter_size=(5, 5), \n",
    "                                      W=weights_in_1, \n",
    "                                      nonlinearity=lasagne.nonlinearities.tanh)\n",
    "    \n",
    "    #drop_1 = lasagne.layers.DropoutLayer(conv_1, p=0.2)\n",
    "    \n",
    "    \n",
    "    pool_1 = lasagne.layers.MaxPool2DLayer(conv_1, pool_size=(2, 2))\n",
    "    \n",
    "    \n",
    "    conv_2 = lasagne.layers.Conv2DLayer(pool_1, num_filters=32, filter_size=(5, 5), \n",
    "                                      W=weights_1_2, \n",
    "                                      nonlinearity=lasagne.nonlinearities.tanh)\n",
    "    \n",
    "    #drop_2 = lasagne.layers.DropoutLayer(conv_2, p = 0.2)\n",
    "    \n",
    "    pool_2 = lasagne.layers.MaxPool2DLayer(conv_2, pool_size=(2, 2))\n",
    "        \n",
    "    act_out = lasagne.layers.DenseLayer(pool_2, 7, \n",
    "                                        W=weights_2_out,\n",
    "                                        nonlinearity=lasagne.nonlinearities.softmax)\n",
    "   \n",
    "    # Method 1: use model.get_output(from lasagne or Theano)\n",
    "    #prediction = lasagne.layers.get_output(act_out)\n",
    "    \n",
    "    # Method 2: add one determininstic layer right after the final dense connection layer\n",
    "    prediction = pm.Deterministic('p', lasagne.layers.get_output(act_out))\n",
    "    \n",
    "    #p = pm.Deterministic('p', T.nnet.softmax(net_out))\n",
    "    # Binary classification -> Bernoulli likelihood\n",
    "    out = pm.Categorical('out', \n",
    "                       prediction,\n",
    "                       observed=(ann_output_minibatch),\n",
    "                        total_size = total_size)\n",
    "    ### Whether or not to flatten the prediction differs between Bernoulli and Categorical Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = inf: 100%|██████████| 3500/3500 [22:39<00:00,  2.37it/s]\n",
      "Finished [100%]: Average Loss = 7.8561e+07\n"
     ]
    }
   ],
   "source": [
    "with neural_network:\n",
    "    # Run ADVI which returns posterior means, standard deviations, and the evidence lower bound (ELBO)\n",
    "    inference = pm.ADVI()\n",
    "    approx = pm.fit(n=3500, method=inference,callbacks=[pm.callbacks.CheckParametersConvergence(diff='absolute')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14df17b90>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdkAAAFTCAYAAAB1bHa8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIInIAkASkQWAJCILAEn+F4c5qQ2SqJ8PAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x163572d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(approx.hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x= T.tensor4('X')\n",
    "\n",
    "# symbolic number of samples is supported, we build vectorized posterior on the fly\n",
    "n = T.iscalar('n')\n",
    "# Do not forget test_values or set theano.config.compute_test_value = 'off'\n",
    "#x.tag.test_value = np.empty_like(X_train[:10])\n",
    "x.tag.test_value = np.empty_like(X_train)\n",
    "n.tag.test_value = 100\n",
    "\n",
    "_sample_proba = approx.sample_node(neural_network.out.distribution.p,\n",
    "                                   size=n,\n",
    "                                   more_replacements={ann_input_minibatch: x})\n",
    "# It is time to compile the function\n",
    "# No updates are needed for Approximation random generator\n",
    "# Efficient vectorized form of sampling is used\n",
    "sample_proba = theano.function([x, n], _sample_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pred = sample_proba(X_test, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pred_ = pred.mean(axis = 0)\n",
    "\n",
    "a = pred_\n",
    "\n",
    "a[np.arange(len(a)),a.argmax(1)] = -1 \n",
    "\n",
    "a[np.arange(len(a)),a.argmax(1)] = 1\n",
    "\n",
    "a[np.arange(len(a)),a.argmin(1)] = 1\n",
    "\n",
    "a[a != 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.401428571429\n",
      "Convergence Error: 6.675\n",
      "Label Ranking loss: 0.7595\n",
      "F1-scores(Weighted) 0.240862839718\n",
      "F1-scores(Micro) 0.284987277354\n",
      "F1-scores(Macro) 0.23310328587\n",
      "F1-scores(Samples) 0.2825\n",
      "Average Precision 0.416189208963\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "print 'Hamming Loss:', hamming_loss(y_test, a)\n",
    "print 'Convergence Error:', coverage_error(y_test, a)\n",
    "print 'Label Ranking loss:', label_ranking_loss(y_test, a)\n",
    "print 'F1-scores(Weighted)', f1_score(y_test, a, average='weighted')\n",
    "print 'F1-scores(Micro)', f1_score(y_test, a, average='micro')\n",
    "print 'F1-scores(Macro)', f1_score(y_test, a, average='macro')\n",
    "print 'F1-scores(Samples)', f1_score(y_test, a, average='samples')\n",
    "print 'Average Precision', average_precision_score(y_test,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Uncert = pred.std(axis = 0)\n",
    "b = Uncert\n",
    "\n",
    "b[np.arange(len(b)), b.argmin(1)] = 2 \n",
    "\n",
    "b[np.arange(len(b)), b.argmin(1)] = 1\n",
    "\n",
    "b[np.arange(len(b)), b.argmax(1)] = 1\n",
    "\n",
    "b[b != 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.395714285714\n",
      "Convergence Error: 6.8\n",
      "Label Ranking loss: 0.755333333333\n",
      "F1-scores(Weighted) 0.220816947075\n",
      "F1-scores(Micro) 0.295165394402\n",
      "F1-scores(Macro) 0.209199096897\n",
      "F1-scores(Samples) 0.293333333333\n",
      "Average Precision 0.389461472978\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "print 'Hamming Loss:', hamming_loss(y_test, b)\n",
    "print 'Convergence Error:', coverage_error(y_test, b)\n",
    "print 'Label Ranking loss:', label_ranking_loss(y_test, b)\n",
    "print 'F1-scores(Weighted)', f1_score(y_test, b, average='weighted')\n",
    "print 'F1-scores(Micro)', f1_score(y_test, b, average='micro')\n",
    "print 'F1-scores(Macro)', f1_score(y_test, b, average='macro')\n",
    "print 'F1-scores(Samples)', f1_score(y_test, b, average='samples')\n",
    "print 'Average Precision', average_precision_score(y_test,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "softmax_prob = pred.mean(axis = 0)\n",
    "c = (softmax_prob / Uncert) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "d = c\n",
    "d[np.arange(len(d)),d.argmax(1)] = -1 \n",
    "\n",
    "d[np.arange(len(d)),d.argmax(1)] = 1\n",
    "\n",
    "d[np.arange(len(a)),d.argmin(1)] = 1\n",
    "\n",
    "d[d != 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.401428571429\n",
      "Convergence Error: 6.75\n",
      "Label Ranking loss: 0.759\n",
      "F1-scores(Weighted) 0.151181696006\n",
      "F1-scores(Micro) 0.284987277354\n",
      "F1-scores(Macro) 0.14006969923\n",
      "F1-scores(Samples) 0.285\n",
      "Average Precision 0.5758206197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "print 'Hamming Loss:', hamming_loss(y_test, d)\n",
    "print 'Convergence Error:', coverage_error(y_test, d)\n",
    "print 'Label Ranking loss:', label_ranking_loss(y_test, d)\n",
    "print 'F1-scores(Weighted)', f1_score(y_test, d, average='weighted')\n",
    "print 'F1-scores(Micro)', f1_score(y_test, d, average='micro')\n",
    "print 'F1-scores(Macro)', f1_score(y_test, d, average='macro')\n",
    "print 'F1-scores(Samples)', f1_score(y_test, d, average='samples')\n",
    "print 'Average Precision', average_precision_score(y_test,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
